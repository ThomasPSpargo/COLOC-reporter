#####
# Author: Thomas Spargo (thomas.spargo@kcl.ac.uk)
# Obtained from GitHub repository: https://github.com/ThomasPSpargo/COLOC-reporter
#
# This script performs colocalisation analysis between two traits at a specified genomic region. 
# Preprocessing and finemapping are handled per-trait and colocalisation analysis is performed with the COLOC software, either using coloc.abf or coloc.susie.
#####
suppressPackageStartupMessages(library(optparse))

option_list = list(
  
  #General options
  make_option("--LAVAfile", action="store", default=NA, type='character',
              help='Path to bivariate genetic correlation summary generated by LAVA. The script extract the locus with the smallest p-value by default. To analyse other genomic regions use the --set_locus option. If --set_locus specifies a comma separated genomic region directly list of the format "chromosome,start_position,end_position" (e.g. 17,43460501,44865832) then no --LAVAfile is required.'),
  make_option("--plink", action="store", default='plink', type='character',
              help="Path to PLINK executable (syntax written for PLINK 1.9). By default, has the value 'plink'"),
  make_option("--traits", action="store", default=NULL, type='character',
              help="Comma separated list of IDs for traits to analyse (e.g. 'P1,P2'), as relevant to the summary statistics defined in the  --GWASconfig input file."),
  make_option("--set_locus", action="store", default=NA, type='character',
              help='Specify target locus to test, either as a number referring to a locus from --LAVAfile, or as a comma separated list of the format "chromosome,start_position,end_position" (e.g. 17,43460501,44865832).'),
  make_option("--LDreference", action="store", default=NA, type='character',
              help="Path to, and prefix for, per-chromosome PLINK binary files used to compute LD matrix for SNPs in region. This input is used by SuSiE. Expected format of <prefix>i.bim, where i is the chromosome number"),
  make_option("--GWASconfig", action="store", default=NULL, type='character',
              help="Path to file specifying configuration of GWAS sumstats. Configuration will be determined by identifying rows whose IDs match the --traits option."),
  make_option("--runMode", action="store", default="trySusie", type='character',
              help="Character string, any of 'trySusie', 'skipSusie', 'doBoth','finemapOnly'.\nIf 'doBoth', both coloc.abf and coloc.susie will attempt to run.\nIf 'trySusie' coloc.susie will be used if SuSiE finemapping identifies at least 1 credible set in each trait and coloc.abf is returned otherwise.\nIf 'skipSusie', only coloc.abf will be applied, and processes necessary for coloc.susie are skipped (e.g. no need to call to plink and generate LD matrix); the LD reference will however still still used for SNP alignment.\nIf 'finemapOnly' then univariate finemapping is performed which can be applied across any number of traits. Note however that only snps in common across all traits and the reference panel will be retained. Therefore, for colocalisation analysis it may be preferable to harmonise summary statistics used in colocalisation analysis pairwise."),
  make_option("--force_matrix", action="store", default=FALSE, type='logical',
              help="If TRUE, the LD matrix will always be recomputed using PLINK. If FALSE, the default, the LD matrix will only be computed if the expected ld_matrix.snplist and ld_matrix.ld files are absent from the <output>/LDmatrix directory."),
  make_option("--finemapQC_handleBetaFlips", action="store", default="drop", type='character',
              help="The SuSiE kriging_rss function is used to check whether observed Z-scores (calculated from beta and SE) correspond with expected Z-scores based on information from the LD matrix and other SNPs. This check indicates if any SNP effect estimates appear like they may be reversed. Set this option to 'flip' to automatically reverse the direction of betas with test statistics identified as inverted on a trait-by-trait basis, or to 'drop' to remove them from all traits across analyses; the option defaults to 'drop'. The check for potentially flipped alleles will be performed but the data used for subsequent analysis will be unchanged if any other strings are passed to this option. Note that the setting applied here will affect both the finemapping and colocalisation analysis steps, but will only be applied in circumstances when SuSiE finemapping is performed."),
  make_option("--finemap_CScoverage", action="store", default=0.95, type='numeric',
              help="Numeric between 0 and 1 to indicate the credible set threshold to use for finemapping; defaults to 0.95, which returns 95% credible sets."),
  make_option("--finemap_refine", action="store", default=FALSE, type='logical',
              help="Logical, defaulting to FALSE. Specify TRUE to add a refinement step to SuSiE finemapping call to avoid identification of local maxima."),
  make_option("--finemap_initialL", action="store", default=10, type='numeric',
              help="Numeric, defaulting to 10, which is the susie default, to indicate the maximum number of non-zero effects to allow in the initial susie regression model."),
  make_option("--finemap_increaseL", action="store", default=TRUE, type='logical',
              help="Logical, defaulting to TRUE which indicates that higher values of L should be attempted in susie finemapping (with L+10 for each loop) when the number of credible sets found match the current L value. Setting this to FALSE will run susie once only, using the L setting specified in the --finemap_initialL option."),
  make_option("--priors_susie", action="store", default=NULL, type='numeric',
              help="Set a prior probability that a snp is causal for susie finemapping (equivalent to coloc p1 or p2). Set to NULL by default which corresponds to the default for the coloc::runsusie wrapper around susie_rss; this is not usual default for susie_rss - see coloc::runsusie documentation for details."),
  make_option("--priors_coloc.abf", action="store", default="1e-4,1e-4,1e-5", type='character',
              help="Comma separated list of 3 numerics indicating priors to set respectively for p1,p2,p12 in coloc.abf function; default values are '1e-4,1e-4,1e-5' which corresponds with the coloc.abf default settings."),
  make_option("--priors_coloc.susie", action="store", default="1e-04,1e-04,5e-06", type='character',
              help="Comma separated list of 3 numerics indicating priors to set respectively for p1,p2,p12 in coloc.susie function; default values are '1e-04,1e-04,5e-06' which corresponds with the coloc.susie default settings (passed through to coloc.bf_bf function)."),
  make_option("--out", action="store", default="./COLOC-reporter", type='character',
              help="Path and prefix for directory in which to return all outputs. Defaults to ./COLOC-reporter. When running multiple analyses, unique output directories are essential for tidy file organisation."),
  make_option("--genomeAlignment", action="store", default=37, type='numeric',
              help="Indicate the reference genome to which summary statistics and LD reference are aligned. Defaults to 37."),
  make_option("--gene_tracks", action="store", default=NULL, type='numeric',
              help="Numeric. Specify the threshold at which plotting of nearby genes changes from one gene per row to plotting multiple genes across individual rows, labelling genes with geom_text_repel. Defaults to NULL, where per-row plotting has no upper limit. Specify 1 to always plot multiple genes per row, provided their genomic positions do not overlap [work in progress]."),
  make_option("--restrict_nearby_gene_plotting_source", action="store", default=NULL, type='character',
              help="Comma delimited character string indicating sources from which nearby genes included in plots are retrieved. Check output tables 'external_gene_source' column for options. Included as an option to reduce overplotting of obscure gene symbols. If NULL, the default, all sources will plot"),
  make_option("--scriptsDir", action="store", default=NULL, type='character',
              help="Filepath to directory script and subdirectory dependencies (note: expects the subdirectories 'helper_functions' (containing custom functions) and 'rmd' (for rmarkdown report templates)")
)

opt = parse_args(OptionParser(option_list=option_list))

#######
### Begin script
#######

suppressPackageStartupMessages({
  library(tidyverse)
  library(data.table) #To read in the datasets
  library(R.utils)    #Required reading gz files directly with fread
  library(coloc)
  library(susieR)
  library(biomaRt)    #For ensembl library
  library(ggrepel)
  library(patchwork)     #arranging summary plot
})

test <- FALSE # test <- TRUE
if(test==TRUE){
  #####
  setwd("/Users/tom/OneDrive - King's College London/PhD/PhD project/COLOC/git.local.COLOC-reporter/testing")
  opt <- list()
  
  # # #TESTING V3
  opt$set_locus <- "17,43460501,44865832"
  opt$GWASconfig <- "./GWAS_samples_testing.txt"
  opt$out <- "./tidy_processingTEST_PD.SZ.chr17"
  opt$traits <- "PD,SZ"#,ALS"
  
  opt$LDreference <- './EUR_phase3_chr'
  opt$runMode <- 'doBoth'
  opt$force_matrix <- FALSE
  
  opt$finemapQC_handleBetaFlips <- 'drop'
  opt$finemap_CScoverage <- 0.95
  
  opt$gene_tracks <- 40
  opt$restrict_nearby_gene_plotting_source <- "HGNC Symbol"
  opt$genomeAlignment <- 37
  
  opt$scriptsDir <- "/Users/tom/OneDrive - King's College London/PhD/PhD project/COLOC/git.local.COLOC-reporter/scripts"
  
  opt$priors_coloc.abf <- "1e-4,1e-4,1e-5"
  opt$priors_coloc.susie <-"1e-04,1e-04,5e-06"
  
  opt$finemap_initialL <- 10
  opt$finemap_increaseL <- TRUE
  opt$finemap_refine <- FALSE
  
}

#Extract names of traits compared, first dropping file path, and then any prefixes indicated by a preceding underscore
traits <- strsplit(opt$traits,",")[[1]]

coveragePcent<- paste0(opt$finemap_CScoverage*100,"%")

#Read in the configuration options
GWASconfig<- fread(opt$GWASconfig)
Config_msg <- paste0("Summary statistic configuration options set according to the specification of --GWASconfig for trait IDs: ", paste0(1:length(traits)," = ",traits,collapse = ", "),".\n",sep='')

#Assign names to traits
names(traits) <- GWASconfig[traits,on="ID"]$traitLabel

opt$out <- paste0(opt$out,"_coloc")
if(!dir.exists(opt$out)){dir.create(opt$out,recursive = TRUE)}

#Set up directories across which outputs are returned
figdir <- file.path(opt$out,"plots")
if(!dir.exists(figdir)){dir.create(figdir)}
tabdir <- file.path(opt$out,"tables")
if(!dir.exists(tabdir)){dir.create(tabdir)}
datadir <- file.path(opt$out,"data")
if(!dir.exists(datadir)){dir.create(datadir)}
reportdir <- file.path(datadir,"reports")
if(!dir.exists(reportdir)){dir.create(reportdir)}
if(opt$runMode %in% c("trySusie", "doBoth","finemapOnly")){
  finemapQCdir <- file.path(opt$out,"finemapQC")
  if(!dir.exists(finemapQCdir)){dir.create(finemapQCdir)}
}


logfile <- file.path(opt$out,'colocalisation.log')

#Setup a colour palette to be used across ggplots (colours taken from plot SuSiE)
ggpalette = c("dodgerblue2", "green4", "#6A3D9A", "#FF7F00", 
              "gold1", "skyblue2", "#FB9A99", "palegreen2", "#CAB2D6", 
              "#FDBF6F", "gray70", "khaki2", "maroon", "orchid1", "deeppink1", 
              "blue1", "steelblue4", "darkturquoise", "green1", "yellow4", 
              "yellow3", "darkorange4", "brown")

sink(file = logfile, append = F)
cat(
  '#################################################################
# colocaliseRegion.R
# Perform colocalisation analysis between GWAS summary statistics in a predetermined genomic region.
# Colocalisation leverages the COLOC and SuSiE software packages.
# Genetic regions must either identified manually or can be selected based on output from LAVA software.
# Documentation for options for running the script can be called with: Rscript ./colocaliseRegion.R --help
# 
# This script was written by Thomas Spargo (thomas.spargo@kcl.ac.uk), please get in touch with any queries.
#
#################################################################
Analysis started at',as.character(Sys.time()),'\n',Config_msg,'Options are:\n')
print(opt)

cat("\n######\n### Setup\n######\n\n")

cat("All outputs will be returned in the directory: ", opt$out,"\n")
cat("Figures from the main analysis steps are returned within the subdirectory: ",basename(figdir),"\n")
cat("Tabular summaries are in the subdirectory: ",basename(tabdir),"\n")
if(opt$runMode %in% c("trySusie", "doBoth","finemapOnly")){
  cat("Finemap quality control checks are in the subdirectory: ",basename(finemapQCdir),"\n")
}
cat("Resources from each main analysis step are in the subdirectory: ",basename(datadir),"\n\n")

sink()

#Read-in custom helper functions stored in directory specified by opt$scriptsDir
list.files(file.path(opt$scriptsDir,"helper_functions"),full.names = TRUE,pattern=".R") %>%
  lapply(.,source) %>%
  invisible(.)

  
######
### Import datasets
######
#Import datasets and convert to tibbles
sums <- lapply(GWASconfig[traits,on="ID"]$FILEPATH,function(x){tibble(fread(x))})
names(sums) <- traits

#Loop across traits to test whether column names match those indicated in the config file
colcheck<- mapply(function(x,trait){
  #Check for column name options match the dataset, warn if not
  colcheck <-  which(!(
    c(GWASconfig[trait,on="ID"]$p_col,
      GWASconfig[trait,on="ID"]$stat_col,
      GWASconfig[trait,on="ID"]$N_col,
      GWASconfig[trait,on="ID"]$chr_col,
      GWASconfig[trait,on="ID"]$pos_col,
      GWASconfig[trait,on="ID"]$se_col,
      GWASconfig[trait,on="ID"]$snp_col,
      GWASconfig[trait,on="ID"]$freq_col)
    %in% colnames(x)
  ))
  return(colcheck)
},x=sums,trait=traits)

colProblem<- sapply(colcheck,length)>0
if(any(colProblem)){
  sink(file = logfile, append = T)
  warning("The column names expected based on the --GWASconfig options set for trait(s): ", paste0(names(colProblem)[colProblem],collapse=", "), " do not match columns detected in the file. Please check the option(s) specified.")
  sink()
}

#Adjust column names into COLOC format.
#mapply is set to SIMPLIFY=FALSE to ensure a list result
sums<- mapply(function(x,trait){
  #Unless specified to be an odds ratio, rename as beta
  if(GWASconfig[trait,on="ID"]$stat_col=="OR"){
    x$beta <- log(x$OR)
    x$OR <- NULL
  } else {
    names(x)[names(x)==GWASconfig[trait,on="ID"]$stat_col] <- "beta"
  }
  
  #Rename the other columns  
  names(x)[names(x)==GWASconfig[trait,on="ID"]$p_col] <- "pvalues"
  names(x)[names(x)==GWASconfig[trait,on="ID"]$N_col] <- "N"
  names(x)[names(x)==GWASconfig[trait,on="ID"]$chr_col] <- "chr"
  names(x)[names(x)==GWASconfig[trait,on="ID"]$pos_col] <- "pos"
  names(x)[names(x)==GWASconfig[trait,on="ID"]$se_col] <- "SE"
  names(x)[names(x)==GWASconfig[trait,on="ID"]$snp_col] <- "snp"
  names(x)[names(x)==GWASconfig[trait,on="ID"]$freq_col] <- "MAF"
    
  return(x)
},x=sums,trait=traits,SIMPLIFY=FALSE)


########
#### Identify region for analysis
########
if(!is.na(opt$set_locus)){
  
  opt$set_locus <- as.numeric(strsplit(opt$set_locus,",")[[1]])
  
  if(length(opt$set_locus)==3){
    #Set genomic positions manually
    reg_range <-c(chr=opt$set_locus[1],
                   start=opt$set_locus[2],
                   stop=opt$set_locus[3])
    
  } else if(length(opt$set_locus)!=1) {
    stop('The option --set_locus is defined but cannot be identified as specifying a genomic region manually (in the comma separated format "chromosome,start_position,end_position") or as single numeric referring to local genetic correlation locus from LAVA')
  } else {
    
    if(is.na(opt$LAVAfile)){
      stop('please set the option --LAVAfile when passing a single numeric in the --set_locus option; this numeric refers to the genomic region flagged by the locus number from LAVA.\n\nNote that --set_locus also accepts a manually defined genomic region (in the comma separated format "chromosome,start_position,end_position"), and the --LAVAfile option is ignored in this circumstance')
    }
    
    #Read the lava input, and extract the locus named
    LAVAfile <- tibble(fread(opt$LAVAfile))
    LAVAregion <- which(LAVAfile$locus==opt$set_locus)
    
    reg_range <-c( chr=LAVAfile$chr[LAVAregion],
                   start=LAVAfile$start[LAVAregion],
                   stop=LAVAfile$stop[LAVAregion])
  }
} else {
  #Read the lava input, and extract the locus with the smallest p-value
  LAVAfile <- tibble(fread(opt$LAVAfile))
  LAVAregion <- which(LAVAfile$p==min(LAVAfile$p))
  
  reg_range <-c( chr=LAVAfile$chr[LAVAregion],
                 start=LAVAfile$start[LAVAregion],
                 stop=LAVAfile$stop[LAVAregion])
}

target_region <- paste0("Chr",reg_range["chr"],":",reg_range["start"],"-",reg_range["stop"])

sink(file = logfile, append = T)
cat(paste0("Colocalisation analysis will be performed for the region: ", target_region," \n"))
sink()

######
# Harmonise summary statistics with reference
######

# Define function to flip sumstat direction to match alleles across gwas and reference,
# Allele frequency is not reversed since coloc utilises MAF.
alignSS <- function(ss,bim){
  ss_bim_match<-merge(ss, bim, by.x=c('snp','A1','A2'), by.y=c('V2','V5','V6'))
  ss_bim_swap<-merge(ss, bim, by.x=c('snp','A1','A2'), by.y=c('V2','V6','V5'))
  
  ss<-ss[ss$snp %in% ss_bim_match$snp | ss$snp %in% ss_bim_swap$snp,] 
  ss$beta[ss$snp %in% ss_bim_swap$snp] <- -ss$beta[ss$snp %in% ss_bim_swap$snp]
  
  return(ss)
}

# Read in reference SNP data to match alleles 
bim<-fread(paste0(opt$LDreference,reg_range["chr"],'.bim'))

#Return total snps available
snpsavail<- lapply(sums,function(x){
  y <- x[x$chr==reg_range["chr"] &
         x$pos>=reg_range["start"] &
         x$pos<=reg_range["stop"],]
  nrow(y)})
sink(file = logfile, append = T)
cat("Total number of SNPs for each sumstats in tested region:\n", paste0(names(snpsavail)," = ",snpsavail,collapse = "\n"),"\n\n",sep='')
sink()
rm(snpsavail)

#Filter to snps in the define chromosome:position range and present in the LD reference data
#Mutate to calculate minor allele frequency and varbeta.
sums.region <- lapply(sums, function(x){
  x %>%
    filter(chr==reg_range["chr"],
           pos>=reg_range["start"],
           pos<=reg_range["stop"],
           snp %in% bim[["V2"]]
    ) %>%
    arrange(match(snp, bim[["V2"]])) %>%
    mutate(MAF=if_else(MAF>0.5,1-MAF,MAF),
           varbeta = SE^2) %>%
    alignSS(.,bim)
    
})

#Return snps available after harmonising with sumstats
snpsavail<- lapply(sums.region,nrow)
sink(file = logfile, append = T)
cat("Number of SNPs in common between LD reference and each set of sumstats in tested region:\n", paste0(names(snpsavail)," = ",snpsavail,collapse = "\n"),"\n",sep='')
sink()
rm(snpsavail)

#Intersect the snp lists to find those common across traits
snplist <- Reduce(intersect,lapply(sums.region,function(x){x$snp}))
sink(file = logfile, append = T)
#Print some information to console
cat(paste0("N SNPs in common across traits after harmonising to LD reference: ", length(snplist),"\n"))
if(length(snplist)==0){cat("Analysis stopped as no SNPs remain.\n");stop("Analysis stopped as no SNPs remain.")}
sink()



#Intersect the overlapping SNPs, and assign sequence position in common snp sequence (based on rownumber).
sums.region <- lapply(sums.region, function(x){x %>%
    filter(snp %in% snplist) %>%
    mutate(position = row_number())
})

snpid<- lapply(sums.region,function(x){paste0(x$snp,"_",x$pos)})
#Return warning if the SNP position alignment seems incorrect.
#sapply compares for identical results across all vectors relative the first vector
if(!all(sapply(snpid[-1],identical, snpid[[1]]))){
  sink(file = logfile, append = T)
  cat("WARNING: SNP names and genomic positions do not match between all datasets. Please check that these have been aligned correctly.")
  sink()
}
rm(snpid)

######
# Generate LD matrix (for SuSiE)
######

if(opt$runMode %in% c("trySusie", "doBoth","finemapOnly")){
  #Extract snps and write list to file in subdirectory of results directory
  
  #Check for the expected LD matrix output; if files are absent or if --force_matrix is set, generate using PLINK
  expect <- c(".snplist",".ld")
  expect <- file.path(opt$out,'LDmatrix',paste0('ld_matrix',expect))
  
  if(any(!file.exists(expect)) | opt$force_matrix){
    
    sink(file = logfile, append = T)
    cat("Computing LD matrix...")
    sink()
    
    ld_dir<- dirname(expect[1])
    
    if(!dir.exists(ld_dir)){dir.create(ld_dir,recursive = TRUE)}
    write(snplist, file=file.path(ld_dir,"snplist.txt"))
    
    #Identify LD matrixsnps from snplist present in reference
    #Syntax based on plink v 1.9
    system(paste0(opt$plink,' --bfile ', opt$LDreference,reg_range["chr"],
                  ' --extract ',ld_dir,'/snplist.txt',
                  ' --r square',
                  ' --write-snplist',
                  ' --keep-allele-order',
                  ' --out ',file.path(ld_dir,'ld_matrix')))
    
    sink(file = logfile, append = T)
    cat("Done\n")
    sink()
    
  } else {
    sink(file = logfile, append = T)
    cat("Existing LD matrix found, skipping call to PLINK.\n")
    sink()
  }
  
  #Read in the ld matrix and snp names as returned by plink 
  ld <- as.matrix(fread(expect[2]))
  ld_names<- scan(expect[1],what=character())
  dimnames(ld)<-list(ld_names, ld_names) #assign dimnames to LD object
  
  #As a sanity check, redo alignment based on plink output order to ensure snps are correctly arranged in base pair order, and assign 'positions' for coloc
  sums.region <- lapply(sums.region, function(x){
    x %>%
      filter(snp %in% ld_names) %>%
      arrange(match(snp, ld_names)) %>%
      mutate(position = row_number())
  })

} 

######
# Generate a minimal dataset across traits which can be readily used for generation of summary plots
# This will be saved to file following the SuSiE steps where a column for credible sets may be appended
######
minimal_df<- mapply(function(x,trait){
  
  mindf<- cbind(x[,c("snp","A1","A2","chr","pos","beta","SE","pvalues")],trait) #Subset to useful columns
  mindf$z <- mindf$beta/mindf$SE #Calculate z-scores
  
  return(mindf)
},sums.region,traits, SIMPLIFY = FALSE) %>%
  do.call(rbind,.) 


######
### Prepare for colocalisation analysis; convert each data.frame to list and add expected list elements
######

##Expected elements:
#LD matrix (if passing via SuSiE)
#type = "cc" or "quant" depending on trait type
#s = case control proportion if "cc"
#Adjust column names into COLOC format.
#mapply is set to SIMPLIFY=FALSE to ensure a list result
sums.region<- mapply(function(x,trait){
  
  x <- as.list(x)
  x$type <- tolower(GWASconfig[trait,on="ID"]$type)
  if(x$type=="cc"){x$s <- GWASconfig[trait,on="ID"]$prop
  } else if(x$type=="quant" && !is.na(GWASconfig[trait,on="ID"]$traitSD)){x$sdY <- GWASconfig[trait,on="ID"]$traitSD}
  if(opt$runMode %in% c("trySusie", "doBoth","finemapOnly")){x$LD <- ld}
  
  #Save the formatted dataset as a resource
  datasetpath<- file.path(datadir,"datasets")
  if(!dir.exists(datasetpath)){dir.create(datasetpath)}
  saveRDS(x,file=file.path(datasetpath,paste0("coloc_format_dataset_",trait,".Rds")))
  
  return(x)
},x=sums.region,trait=traits,SIMPLIFY=FALSE)

######
### Extract genes around tested region
######

#Import gene information for region
ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl", GRCh=opt$genomeAlignment)
Genes<-getBM(attributes=c('external_gene_name','chromosome_name','start_position','end_position','external_gene_source','strand'), mart = ensembl)

# Use 10kb window to define gene window
gene_window<-10000
Genes$start_window<-Genes$start_position-gene_window
Genes$end_window<-Genes$end_position+gene_window

# Do main Susie steps
if(opt$runMode %in% c("trySusie", "doBoth","finemapOnly")){
  
  sink(file = logfile, append = T)
  cat("\n######\n### SuSiE finemapping quality control\n######\n")
  sink()
  
  ## Add initial elements to the finemapping reports.
  
  #The number of SNPs in the datasets prior to finemapping QC, the cs coverage, genome alignment, the name of each trait.
  invisible(mapply(assignToList,x=paste0("RMD_finemap_",traits),value=traits,name="trait"))
  invisible(lapply(paste0("RMD_finemap_",traits),assignToList,value=length(sums.region[[1]]$snp),name="initNsnp"))
  invisible(lapply(paste0("RMD_finemap_",traits),assignToList,value=coveragePcent,name="coverage"))
  invisible(lapply(paste0("RMD_finemap_",traits),assignToList,value=opt$genomeAlignment,name="alignment"))
  
  #Nominal exclusion boundary [option under-testing, may not make sense]
  #opt$finemapQC_dropZOutliers <- NA#3
  
  susieQC <- mapply(function(dset,trait){
      ## Compare observed z-scores with LD matrix [warning thrown when LD matrix is not semi-definite...]
      z_sc <- dset$beta/dset$SE #Get z-scores
      
      # #Estimate s with all available methods - indicates compatibility between sumstats and reference
      checkMthd<- c("null-mle", "null-partialmle", "null-pseudomle")
      checkLD<- sapply(checkMthd,estimate_s_rss,z=z_sc, R=dset$LD, n=max(dset$N), r_tol = 1e-08)
      
      #Add extra info for writing to file
      checkTofile<- c("trait"= trait, "any_flips"=FALSE,round(checkLD,5))
      
      #Write finemapping summary to a file and write without names if file exists already
      LDcheckFile<- file.path(finemapQCdir,"check_sumstat_LDconsistency.csv")
      write.table(t(checkTofile),
                  file=LDcheckFile,sep = ",", row.names=FALSE,col.names = !file.exists(LDcheckFile),append = file.exists(LDcheckFile))
      
      ### Check for allele flip issues
      #Compare observed and expected Z-scores
      z_compare<- kriging_rss(
        z=z_sc,
        R=dset$LD,
        n=max(dset$N),
        r_tol = 1e-08,
        s = checkLD[[1]]
      )
      zPlot<- z_compare$plot
      
      # if(!is.na(opt$finemapQC_dropZOutliers)){
      #   
      #   #Add hatched lines to plot at exclusion boundaries
      #   zPlot <- zPlot+  
      #     geom_abline(slope=1,intercept=opt$finemapQC_dropZOutliers,lty=2)+
      #     geom_abline(slope=1,intercept=-opt$finemapQC_dropZOutliers,lty=2)
      #   
      #   ## Compare the difference between observed and expected z-scores
      #   diffs<-  with(z_compare$conditional_dist,
      #                 abs(z-condmean))
      #   exclIndex<- diffs>opt$finemapQC_dropZOutliers #Identify index positions for 'out of bounds' Z-score snps
      #   
      # } else {
      #  exclIndex = NULL
      # }
      
      #Determine snps with betas that may be flipped; this check corresponds with the one implemented by internally by kriging_rss
      possFlipped<- with(z_compare$conditional_dist,
                         logLR>2 & abs(z)>2)
      nPossFlipped<- sum(possFlipped)
      
      if(nPossFlipped>0){ #If any outliers replot the figure in a circumstance where these are flipped
        z_sc_flip <-z_sc
        z_sc_flip[possFlipped]<- -z_sc_flip[possFlipped]
        
        #Repeat s-estimation after flips
        checkLD_flipped<- sapply(checkMthd,estimate_s_rss,z=z_sc_flip, R=dset$LD, n=max(dset$N), r_tol = 1e-08)
        checkTofile_flipped<- c("trait"= trait, "any_flips"=TRUE,round(checkLD_flipped,5)) #Add extra info for writing to file
        
        checkTofile<- cbind(checkTofile,checkTofile_flipped) #Concatenate both versions
        
        
        #Write finemapping summary to a file and write without names if file exists already
        LDcheckFile<- file.path(finemapQCdir,"check_sumstat_LDconsistency.csv")
        write.table(t(checkTofile_flipped),
                    file=LDcheckFile,sep = ",",row.names=FALSE,col.names = !file.exists(LDcheckFile),append = file.exists(LDcheckFile))
        
        #Compare observed and expected Z-scores
        z_compare_flip <- kriging_rss(
          z=z_sc_flip,
          R=dset$LD,
          n=max(dset$N),
          s = checkLD_flipped[[1]] 
        )
        zPlotFlip<- z_compare_flip$plot #Extract plot
        
        # if(!is.na(opt$finemapQC_dropZOutliers)){ #If removing extreme values
        #   #Plot the boundary lines
        #   zPlotFlip <- zPlotFlip +
        #     geom_abline(slope=1,intercept=opt$finemapQC_dropZOutliers,lty=2)+
        #     geom_abline(slope=1,intercept=-opt$finemapQC_dropZOutliers,lty=2)
        #   
        #   ## Compare the difference between observed and expected z-scores
        #   diffs_flipped<-  with(z_compare_flip$conditional_dist,
        #                         abs(z-condmean))
        #   exclIndex_flip<- diffs_flipped>opt$finemapQC_dropZOutliers #Identify index positions for 'out of bounds' Z-score snps
        # } else {
        #   exclIndex_flip = NULL
        # }
        
        #Patchwork combine with and measured flips with and without encoding 
        zPlot<- zPlot+labs(subtitle = "Initial encoding")+
          zPlotFlip+labs(subtitle = "Reversing putative statistic flips")+theme(axis.title.y = element_blank())
        
      } #else {
        #exclIndex_flip = NULL
      #}
      
      #Save the plot
      z_check_outpath <- file.path(finemapQCdir,paste0("Z_score_alignment_",trait,".pdf"))
      ggsave(z_check_outpath,zPlot,device="pdf",units="mm",width=150,height=100)
      
      #Add multiple elements to report:
      #Z-plot 
      #LD 's' consistency check; this could have one or two rows according to whether any potential encoding flips were flagged
      #Number of possible allele flips
      assignToList(x=paste0("RMD_finemap_",trait),multi=TRUE,
                   value=list(nPossFlipped=nPossFlipped,
                              init_s_estimate=data.frame(t(checkTofile)),
                              zPlot=zPlot))
    
      #Report relevant messages to the logfile
      sink(file = logfile, append = T)
      cat("\nQuality control for ",trait,":\n",sep="")
      cat(nPossFlipped,ifelse(nPossFlipped==1," SNP was"," SNPs were")," flagged for potentially flipped allele encoding", ifelse(nPossFlipped>0," (marked red on the diagnostic plot returned in the finemapQC directory).\n",".\n"),sep="")
      # if(!is.na(opt$finemapQC_dropZOutliers)){
      #   cat(sum(exclIndex),ifelse(sum(exclIndex)==1,"SNP was","SNPs were"),"flagged with high discrepancy between expected and observed Z-scores.\n")
      #   if(!is.null(exclIndex_flip)) cat("After repeating check with flipped allele encoding,",sum(exclIndex_flip), "would remain as Z-score outliers.\n")
      # }
      sink()
      
      # #If flipping is to be performed, exclude based on outliers after the flipping stage
      # if(opt$finemapQC_handleBetaFlips=="flip" && !is.null(exclIndex_flip)){
      #   exclIndex<- exclIndex_flip
      # }
      
      #if(is.null(exclIndex)){ #If nothing to exclude, set a vector of FALSE values
        exclIndex <- rep(FALSE,length(dset$snp))
      #}
      
     
      return(list(conditional_dist=z_compare$conditional_dist,toFlip=possFlipped,toExclude=exclIndex))
      
  },sums.region,traits,SIMPLIFY = FALSE)
  
  sink(file = logfile, append = T)
  cat("\nGlobal quality control:\nTests of consistency between each set of sumstats and LD matrix by each method available in SuSiE estimate_s_rss function are written to: check_sumstat_LDconsistency.csv\n")
  cat("Comparisons between observed and expected z-scores are visualised per trait in the file(s): Z_score_alignment_<trait>.pdf. If SuSiE identifies any credible sets, these data will be replotted with colouring to mark credible sets assigned.\n\n")
  sink()
  
  #Across traits, identify if any positions betas are indicated for flipping.
  #If flipping, this will be handled per-trait, if dropping, this will be done by global index
  globalFlips <- Reduce(`|`, lapply(susieQC,function(x) x$toFlip))
  
  #Across traits, identify which positions have been identified as outliers and remove problematic SNPs from all traits
  #This currently does nothing, but object is assigned to prevent any downstream errors
  globalExclude<- Reduce(`|`, lapply(susieQC,function(x) x$toExclude))
  
  #If set, adjust each sumstats to remove or flip outlier records
  if( 
    ( opt$finemapQC_handleBetaFlips %in% c("drop","flip") && any(globalFlips) )# ||
    #( !is.na(opt$finemapQC_dropZOutliers) && any(globalExclude) ) 
  ){
    
    #Logical indicating whether the exclusion step is to be conducted; only if there are records to exclude and if this wouldnt remove ALL records
    #doExcludeStep<- !is.na(opt$finemapQC_dropZOutliers) && any(globalExclude) && any(!globalExclude)
    
    #Logical tests indicating how allele flipping steps should proceed (i.e. with flipping, or with dropping)
    doFlipStep <- tolower(opt$finemapQC_handleBetaFlips)=="flip" && any(globalFlips)
    doFlipDROPStep <- tolower(opt$finemapQC_handleBetaFlips)=="drop" && any(globalFlips) && any(!globalFlips)
    
    #Message about which steps are to be conducted
    sink(file = logfile, append = T)
    if(doFlipStep){ cat("Summary statistic betas will be flipped per-trait for all SNPs indicated to have reversed allele order.\n")
    } else if(doFlipDROPStep){ cat("SNPs identified as likely to have flipped test statistics in any trait will be removed...\n") }
    #if(doExcludeStep) { cat("SNPs flagged as extreme Z-score outliers",ifelse(doFlipStep,"after flipping betas",""),"in any trait will be removed...\n") } 
    sink()
    
    #Across datasets flip betas/drop SNPs according to settings
    sums.region <- mapply(function(dset,QC,trait,globalExcl,flipDrop){
      
      #According to doFlipStep and doFlipDROPStep logicals flip or drop problematic beta coefficients.
      #Flipping is handled on a trait-by-trait basis while dropping is global to keep datasets harmonised
      if(doFlipStep){
        dset$beta[QC$toFlip] <- -dset$beta[QC$toFlip]
      } else if(doFlipDROPStep){
        dset<- dropSNPs(dset,flipDrop)
        globalExcl<- globalExcl[!flipDrop] #If dropping has been performed, then filter the the second exclusion step to ensure correct indexing
      }
      
      # if(doExcludeStep){
      #   #With custom function, remove snps that are marked as candidates for flipping
      #   dset<- dropSNPs(dset,QC$globalExcl)
      # }
      
      return(dset)
    }
    ,sums.region,susieQC,traits,MoreArgs = list(globalExcl=globalExclude,flipDrop=globalFlips),SIMPLIFY = FALSE)
    
    #Save IDs for SNPs that have been dropped to file (if any)
    isDropped<- !snplist %in% sums.region[[1]]$snp
    if(any(isDropped)){
      write(snplist[isDropped],
            file=file.path(finemapQCdir,"FinemapQC_droppedSNPs.txt")
      )}
    
    if(#doExcludeStep || 
      doFlipDROPStep){ #Report message indicating how subsetting
      sink(file = logfile, append = T)
      cat("A total of",length(sums.region[[1]]$snp),"SNPs remain.\n")
      if(any(isDropped)) cat("An index of removed snps can be found in the following file: FinemapQC_droppedSNPs.txt")
      if(length(sums.region[[1]]$snp)==0){cat("Analysis stopped as no SNPs remain.\n");stop("Analysis stopped as no SNPs remain.")}
      sink()
      
    }
  }
  
  #Always return the final number of SNPs in the main report
  invisible(lapply(paste0("RMD_finemap_",traits),assignToList,value=length(sums.region[[1]]$snp),name="finalNsnp"))
  
  # backup_QC_reportPD<- RMD_finemap_PD
  # backup_QC_report_SZ<- RMD_finemap_SZ
  sink(file = logfile, append = T)
  cat("\n######\n### SuSiE finemapping results\n######\n\n")
  sink()
  
  #Run SuSiE across datasets and generate report summaries
  #A guideline for N is specified since this is highly recommended
  
  SusieFail <- logical(0) #SusieFail indicates if susie was successful across traits: TRUE indicates an error was thrown
  susie <- mapply(function(dset,trait){
    L <- opt$finemap_initialL #Define the number of credible sets to initially fit
    
    #Set a list of arguments to pass to runsusie (and internal susieR functions) with do.call
    #Is programmed this way to avoid repetition in any potential while loop for increasing the L argument
    runsusieArgs <- list(d=dset,
                         n=max(dset$N),
                         estimate_residual_variance = FALSE,
                         coverage=opt$finemap_CScoverage,
                         p=opt$priors_susie,
                         refine=opt$finemap_refine,
                         maxit=ifelse(opt$finemap_refine,10000,100),
                         check_prior=TRUE
      )
    
    tryCatch({
      
      #Run Susie
      finemap<- do.call(runsusie,c(runsusieArgs,list(L=L)))
      
      #If the fit indicates a number of CS close to the maximum number of L, recursively try a larger number
      opt$finemap_increaseL <- TRUE
      if(opt$finemap_increaseL){
        while(max(finemap$sets$cs_index)>=L-2){
          L=L+10 #Iteratively increase number
          finemap<- do.call(runsusie,c(runsusieArgs,list(L=L)))
          
          if(L==100) break #Set a very high limit on the loop to avoid potential infinite loop
        }
      }
      #Alternative syntax to run this without the coloc wrapper
      #finemap<- susie_rss(dset$beta/dset$SE,R=dset$LD,n=max(dset$N),refine=TRUE)
      
      ## Some basic diagnostics
      #susie_plot(finemap,y="PIP",add_legend=TRUE) 
      
      #Save the susie results as a resource
      finemappath<- file.path(datadir,"finemapping")
      if(!dir.exists(finemappath)){dir.create(finemappath)}
      saveRDS(finemap,file=file.path(finemappath,paste0("susie_results_",trait,".Rds")))
      
      #Assign FALSE if errors weren't thrown
      assign("SusieFail",c(SusieFail,FALSE),envir=.GlobalEnv)
      
      return(finemap)},
      
      error   = function(x){ #If there is an issue, flag in global environment and print to log file
        warning(x)
        assign("SusieFail",c(SusieFail,TRUE),envir=.GlobalEnv)
        
        sink(file = logfile, append = T)
        cat("------------------------------\n")
        cat("SuSiE fine-mapping error produced for", traits[length(SusieFail)],". Please see the following:\n")
        cat("Error in", toString(last.warning),":\n",names(last.warning),"\n")
        cat("------------------------------\n")
        sink()
      })
  },sums.region,traits,SIMPLIFY = FALSE)
  
  
  
  
  
  ######
  ### Summarise susie results across datasets
  ######
  susie_rep <- mapply(function(susie.fit,dset,trait,failed){
    
    if(failed){ #For a trait with a failed finemapping step, terminate early and return empty list for downstream logic-checks
      return(list(csFound=FALSE,sets=data.frame(snp=snplist,cs=factor(NA_character_),
                                                              variable_prob=NA_real_)))
    } else { #Otherwise, produce a summary!
      
      ## Extract initial summary elements from susie.fit
      sum_susie <- summary(susie.fit)
      csFound<- !is.null(sum_susie$cs) #Logical statement to pass through indicating TRUE if a CS has been identified
      sets<- sum_susie$vars #[sum_susie$vars$cs!=-1,] #Extract all snps
    
      ##Perform a final consistency check for the final dataset
      finalConsistencyCheck<- estimate_s_rss(method="null-mle",z=dset$beta/dset$SE, R=dset$LD, n=max(dset$N), r_tol = 1e-08)
      
      ## Format the dataset subsetting to only the list elements which are snpwise values
      basedata<- as.data.frame(dset[sapply(dset,length)==length(dset$snp)])
      
      #Combine sets object with the basedata, matched by row-index
      sets<- cbind(sets,basedata[sets$variable,c("snp","chr","pos","pvalues","beta","SE")]) #Add relevant columns from GWAS sumstats
      
      #Quick check to catch a potential circumstance where CS have not matched to snp IDs correctly
      sets$setmatch <- sapply(sets$cs,function(x)ifelse(x!=-1,paste0("L",x),NA_character_))
      for(i in seq_along(susie.fit$sets$cs)){
        setName<- names(susie.fit$sets$cs)[i]
        overlaps<- intersect(sets$snp[which(sets$setmatch==setName)],names(susie.fit$sets$cs[[i]]))
        if(length(overlaps)!=length(susie.fit$sets$cs[[i]])){ stop("Fine-mapping credible sets have not been correctly matched to SNPs for the report step. Please report this error since this will be a result of an unexpected issue in the workflow.") }
      }
      sets$setmatch <- NULL
      
      #Save PIP summaries to file
      sets_outpath<- file.path(tabdir,paste0("susie_snp_summary_",trait,".csv"))
      write.table(sets,file=sets_outpath,sep = ",",row.names=FALSE)
      tab_out<- paste0("PIP summaries for SNPs for ",trait," are tabulated in:\n", basename(sets_outpath),"\n") #Info string
      
      ### Plot the pip summaries alongside snp p-values
      
      #Mutate data for plotting
      sets <- sets %>%
        mutate(cs = if_else(cs==-1,NA_character_,paste0("L",cs)),
               thresh = if_else(!is.na(cs),as.character(snp),""))
      
      if(csFound){ #if CS are found
        #Replicate Susie plot legend labelling. Order credible sets numerically for plot visual consistency (numbering is otherwise arbitrary)
        csNames<- names(susie.fit$sets$cs)
        csNames<- csNames[order(as.numeric(gsub("L","",names(susie.fit$sets$cs))))]
        
        CSlen<- sapply(susie.fit$sets$cs,length)[csNames]
        CSmin<- susie.fit$sets$purity[csNames,"min.abs.corr"] #Here matching uses rownames
        csLabs<- paste0(names(CSlen),": C=",CSlen,"/R=",round(CSmin,3))
        
        #Explicit conversion to factor for the CS to ensure correct labelling
        sets$cs <- factor(sets$cs,levels=names(CSlen),labels=csLabs)
      }
      
      pips <- ggSummaryplot(yaxis="pip",
                            xlim=range(sets$pos),
                            dset=sets,colourMapping=switch(csFound,sym("cs"),NULL),
                            nameColourLegend="Credible set",build=paste0("GRCh",opt$genomeAlignment),chr=sets$chr[1])$bpfigure +
        labs(title=ifelse(is.null(names(trait)),trait,names(trait))) #Use trait name as plot title if possible
      
      ggsave(file.path(figdir,paste0("susie_PIP_",trait,".pdf")),pips,device="pdf",units="mm",width=150,height=150)
      
      if(csFound){

        ## Visualise CS-assigned SNPs against the Obs/Exp SNP matrix.
        
        #Generate the obs vs exp Z-scores
        z_compare_cs <- kriging_rss(
          z=dset$beta/dset$SE,
          R=dset$LD,
          n=max(dset$N),
          s=finalConsistencyCheck
        )
        
        #Combine the dset 'snp' vector with the z_compare results (to ensure that the row order is consistent), then add credible sets matched by snp.
        z_compare_csplot<- cbind(dset["snp"],z_compare_cs$conditional_dist) %>%
          left_join(sets[c("snp","cs")],by="snp") %>%
          mutate(alpha=if_else(!is.na(cs),1,0)) %>%
          arrange(desc(is.na(cs)),cs) %>% #Arrange to force plotting of non-NA vals (i.e. CS), atop the non-cs snps)
          ggplot(.,aes(x=condmean,y=z,colour=cs,alpha=alpha))+
          geom_point() +
          theme_bw()+
          labs(y = "Observed z scores", x = "Expected value") +
          geom_abline(intercept = 0, slope = 1) +
          scale_colour_manual(na.value = "black", values=ggpalette,breaks=levels(sets$cs))+
          scale_alpha_continuous(range=c(0.2,1))+
          guides(color=guide_legend(title="Credible set"),alpha="none")
        
        #Save to file
        ggsave(file.path(finemapQCdir,paste0("Z_score_alignment",trait,"_withCS.pdf")),z_compare_csplot,device="pdf",units="mm",width=150,height=150)
        
        ##### Create summary file
        finemap_summary <- data.frame(CS_span = NA,
                                      LD_Zscore_consistency=finalConsistencyCheck,
                                      CScoverage=opt$finemap_CScoverage,
                                      beta_maxSNP = basedata$snp[which(basedata$beta==max(basedata$beta))],
                                      p_minSNP = basedata$snp[which(basedata$pvalues==min(basedata$pvalues))],
                                      pip_maxSNP = NA,
                                      sum_susie$cs,
                                      NSNP=NA,
                                      TopPIP=NA,
                                      Genes_near_span=NA)
        
        for(j in 1:nrow(sum_susie$cs)){
          snp_index<-as.numeric(unlist(strsplit(finemap_summary$variable[j], ',')))
          
          finemap_summary$NSNP[j] <- length(snp_index)
          finemap_summary$TopPIP[j]<-max(susie.fit$pip[snp_index])
          finemap_summary$pip_maxSNP[j]<- paste(names(susie.fit$pip)[susie.fit$pip==finemap_summary$TopPIP[j] & seq_along(susie.fit$pip) %in% snp_index], collapse=', ')
          
          ss_subset<-basedata[(basedata$snp %in% names(susie.fit$pip)[snp_index]),]
          min_bp<-min(ss_subset$pos)
          max_bp<-max(ss_subset$pos)
          chr<-ss_subset$chr[1]
          
          finemap_summary$CS_span[j]<- paste0("chr",chr,":",min_bp,"-",max_bp) #span of credible set
          
          Genes_subset<- Genes[Genes$chromosome_name == chr & (
            (Genes$start_window >= min_bp & Genes$start_window <= max_bp) | #Test if start position is within range
              (Genes$end_window >= min_bp & Genes$end_window <= max_bp) |   #or if end position is within range
              (Genes$start_window <= min_bp & Genes$end_window >= max_bp)   #or if start and end positions are both outside range [gene straddles window]
          ),]

          if(nrow(Genes_subset) > 0){
            #Write the gene names
            finemap_summary$Genes_near_span[j]<-paste(Genes_subset$external_gene_name, collapse=', ')

            #Save details for genes near to credible set #NO MENTION OF THIS OUTPUT IN THE REPORT
            sets_outpath<- file.path(tabdir,paste0("nearby_genes_",trait,"_cs",j,".csv"))
            Genes_subset %>%
              dplyr::select(-c(start_window,end_window)) %>%
              write.table(.,file=sets_outpath,sep = ",",row.names=FALSE)
          }
        }
        finemap_summary$variable <- NULL
        
        #Write finemapping summary to file and concatenate with previous results if file already exists
        finemapSummary<- file.path(tabdir,"results_summary_finemapping.csv")
        write.table(cbind(trait=unname(trait),finemap_summary),
                    file=finemapSummary,sep = ",",row.names=FALSE,col.names = !file.exists(finemapSummary),append = file.exists(finemapSummary))
        
        ## Generate some summary plots
        
        #Select the top snps and cs index
        topsnps<- finemap_summary[c("pip_maxSNP","cs")]
        names(topsnps)[1] <- "topsnp"
        
        #Where multiple top snps have been matched, split into long format dataset
        #some plots will allow inclusion of multiple snps per CS and downsampling is handled internally
        topsnps <- separate_rows(topsnps, all_of("topsnp"), sep = ", ")
        
        ## First, plot LD in the region relative to top snps from the credible set(s) identified
        
        #Visualise the LD between Top PIP SNPs and other SNPs in the dataset / assigned to CS in heatmap
        #The plotting function expects an index of the top snps to plot ("topsnp") and the credible set to which they correspond ("cs")
        ldHeatmap<- susie_cs_ld(sets=sets,R=dset$LD,topsnps=topsnps,heatmapPalette="OrRd",discretePalette=ggpalette,
                                alignment=37,plotR2=TRUE,trait=trait)
        
        ggsave(file.path(figdir,paste0("LD_correlations_withCS_",trait,".pdf")),ldHeatmap$heatmap_allSNPs,device="pdf",units="mm",width=200,height=150)
        ggsave(file.path(figdir,paste0("LD_correlations_withCS_",trait,"_CSsnpsOnly.pdf")),ldHeatmap$heatmap_CSonly,device="pdf",units="mm",width=200,height=150)
        
        #If 2+ CS, visualise correlations between different credible sets
        if(length(susie.fit$sets$cs)>1){
          cs_heatmap <- susieCScorrs(susie.fit,R=dset$LD,inc_Z=TRUE,sets=sets,topsnps =topsnps)
          ggsave(file.path(finemapQCdir,paste0("cs_correlations_",trait,".pdf")),cs_heatmap$heatmap,device="pdf",units="mm",width=150,height=150)
          
          #Save heatmaps to list which will pass to a Rmd report
          assignToList(x=paste0("RMD_finemap_",trait),value=cs_heatmap$heatmap,name="CS_corrmap")
          
        }
        
        #Assign elements relevant to having 1+ cs to report
        assignToList(x=paste0("RMD_finemap_",trait),multi=TRUE,
                     value=list(LDheatmaps=ldHeatmap,
                                zPlot_withCS=z_compare_csplot))
        
      } else {
        finemap_summary <- paste("No",coveragePcent,"credible sets could be identified")
      }
      
      #Append a series of report
      assignToList(x=paste0("RMD_finemap_",trait),multi=TRUE,
                   value=list(niter=susie.fit$niter,
                              converged=susie.fit$converged,
                              final_s_estimate=finalConsistencyCheck,
                              sets=sets,
                              nCS=length(susie.fit$sets$cs),
                              coloc_format_data=dset,
                              finemapSummary=finemap_summary
                              ))
      
      #Sink directly to file
      sink(file = logfile, append = T)
      cat("------------------------------\n")
      cat("SuSiE finemap result for ", trait,":\n",sep="")
      cat("Model fitted using", susie.fit$niter,"iterations, and converged =",susie.fit$converged,"\n\n")
      print(finemap_summary)
      cat("\n",tab_out)
      cat("------------------------------\n")
      sink()
      
      #Return results just in case
      return(list(finemap_summary=finemap_summary,tab_out=tab_out,csFound=csFound, sets=sets))
    }
  },susie,dset=sums.region,trait=traits,failed=SusieFail,SIMPLIFY = FALSE)
  
  
  #Identify the objects storing files to write to a report
  finemapReports<- grep("RMD_finemap_",ls(envir=.GlobalEnv),value=TRUE)
  
  
  #Render the QC report per-trait
  invisible(mapply(renderReport,
         params=finemapReports,
         outfile=file.path(normalizePath(reportdir),paste0("02_",gsub("RMD_","",finemapReports),"_report.html")),
         MoreArgs = list(template=file.path(opt$scriptsDir,"rmd","finemap_report.Rmd"))))
  
  
  
  
  if(file.exists(file.path(tabdir,"results_summary_finemapping.csv"))){
    sink(file = logfile, append = T)
    cat("\nSummaries of credible sets identified by susie across traits are all available in the file: results_summary_finemapping.csv\n")
    sink()
  }
  
  
  #Flag either of the SuSiE calls failed
  if(any(SusieFail)){
    
    ######
    ### Check alignment of Beta and LD, may lead to issues with LD matrix convergence if not aligned in the same direction
    ######
    pdf(file=file.path(finemapQCdir,"Beta_LD_alignment.pdf"),width=7,height=7)
    lapply(sums.region,check_alignment)
    dev.off()
    
    sink(file = logfile, append = T)
    cat("The SuSiE finemapping step returned an error for at least one trait (see above).\n")
    cat("Please check the resources returned in the finemapQC directory to evaluate the  alignment of summary statistic test statistics against those expected given the LD matrix.\nSee also https://chr1swallace.github.io/coloc/articles/a02_data.html for details.\n")
    sink()
    
  } else if(!all(sapply(susie_rep[1:ifelse(length(susie_rep)>2,2,length(susie_rep))],function(x)x$csFound))){ #Return this message on the basis of only the first two traits
    sink(file = logfile, append = T)
    cat(coveragePcent," credible sets were not identified for at least one of ",paste0(traits[1:ifelse(length(traits)>2,2,length(traits))],collapse=" & "),". Therefore, coloc.susie was not used.\nAdjusting the susie_rss coverage parameter using the --finemap_CScoverage option may allow lower coverage credible sets to be identified but these should be treated with caution (See: https://chr1swallace.github.io/coloc/articles/a06_SuSiE.html).\n",sep='')
    sink()
  }
  
  
  #Extract PIPs for each trait 
  snp_PIP <- mapply(function(x,trait,keepcols){cbind(x$sets[,c("snp","variable_prob")],trait)},
                    susie_rep, traits, SIMPLIFY = FALSE) %>%
    do.call(rbind,.) 
  
  #Combine SuSiE PIP results with the minimal dataset
  minimal_df <- right_join(minimal_df,snp_PIP,by=c("snp","trait"))  #add each PIP; but retain only snps passing QC
  
  #If any CS were identified, extract these across traits  and add to the minimal DF
  if(any(sapply(susie_rep,function(x)x$csFound))){
    
    #Extract credible set summaries per-snp across traits.
    #Subset to columns, adjust credible set labels, then reduce list across matched DFs and unite cols
    snp_CS<- mapply(function(x,trait){ 
      y <- x$sets[,c("snp","cs")]
      if(length(levels(y$cs))>0){levels(y$cs) <- paste0(trait,":",gsub("^L([0-9]+)\\:.*","\\1",levels(y$cs)))}
      return(y)
    },susie_rep,traits,SIMPLIFY = FALSE) %>%
      reduce(full_join,by="snp") %>%
      tidyr::unite(.,col=cs, starts_with("cs"), sep = " & ", remove = TRUE, na.rm = TRUE) %>%
      mutate(cs=as.factor(if_else(cs=="",NA_character_,cs)))
    
    #Combine SuSiE credible sets with the minimal dataset
    minimal_df <- right_join(minimal_df,snp_CS,by="snp")
  }
  
  minDFtext<- " with SNPwise finemapping information "
  
} else {
  #If susie is skipped entirely, produce some dummy values required for subsequent logic checks
  susie_rep <- sapply(seq_along(sums.region),function(x)list(csFound=FALSE))
    
  SusieFail <- sapply(seq_along(sums.region),function(x) FALSE)
  
  minDFtext<- " "
  
}

## Save the minimal dataset to file, for later plotting
sink(file = logfile, append = T)
cat("---------\nSaving file containing harmonised summary statistics",minDFtext,"across traits to the file: data/datasets/harmonised_sumstats.csv\n",sep="")
sink()

write.table(minimal_df,file=file.path(datadir,"datasets","harmonised_sumstats.csv"),sep = ",",row.names=FALSE,col.names = TRUE,quote = FALSE)

if(opt$runMode=="finemapOnly"){
  sink(file = logfile, append = T)
  cat("Skipping colocalisation analysis because the 'finemapOnly' setting is declared in the --runMode option.\n")
  sink()
  
} else if(length(traits)==1){
    sink(file = logfile, append = T)
    cat("Skipping colocalisation analysis because only one trait has been provided.\n")
    sink()
    
} else {
  
  #Subset to traits 1 and 2, if more have been supplied for prior steps.
  if(length(traits)>2){
    sink(file = logfile, append = T)
    cat("Colocalisation analysis can only be performed for pairs of traits. Proceeding with the first two traits only.\n")
    sink()
    
    traits<- traits[1:2]
    SusieFail<- SusieFail[1:2]
  }
  
  #Separate into distinct objects consistent with initial script config for downstream analysis.
  #Ensure only the first two datasets are passed onward
  sums1.region <- sums.region[[1]]
  sums2.region <- sums.region[[2]]

######
### Proceed with colocalisation step
######
sink(file = logfile, append = T)
cat("\n######\n### Colocalisation results\n######\n\n")
sink()


## Extract priors for coloc steps [coloc.abf and coloc.susie defaults unless options are otherwise modified]
colocPriors<- strsplit(c(opt$priors_coloc.abf,
                         opt$priors_coloc.susie),split=",")
names(colocPriors) <- c("coloc.abf","coloc.susie") #set names respective to the relevant function

colocPriors <- lapply(colocPriors,function(x){
  x <- as.numeric(x)              #Set to numeric
  names(x) <- c("p1","p2","p12")  #Declare relevant argument name
  x<- as.list(x)                  #Convert to list
  return(x)})

#Character vector to flag which coloc analyses have been performed
coloc_performed <- character(0)

#If either SuSiE call failed, a credible set has not been found for both traits, or if analysis is passed direct to coloc, run coloc.abf
if(any(SusieFail) || !all(sapply(susie_rep[1:ifelse(length(traits)>2,2,length(traits))],function(x)x$csFound)) || opt$runMode %in% c("doBoth","skipSusie")){  
  
  #Run coloc.abf via do.call to allow passing of the priors list
  clc.abf<- do.call(coloc.abf,c(colocPriors$coloc.abf,list(dataset1=sums1.region, dataset2=sums2.region)))
  
  #Save the coloc abf results as a resource
  colocpath<- file.path(datadir,"colocalisation")
  if(!dir.exists(colocpath)){dir.create(colocpath)}
  saveRDS(clc.abf,file=file.path(colocpath,paste0("coloc_abf_",paste0(traits,collapse="_"),".Rds")))

  sink(file = logfile, append = T)
  cat("Colocalisation will now be performed without passing first to SuSiE [see coloc::coloc.abf].\n")
  cat("Thus, the single causal variant assumption has not been relaxed.\n")
  cat("coloc.abf was performed with the following priors:\n")
  print(clc.abf$priors)
  cat("coloc.abf results summary:\n")
  print(clc.abf$summary)
  cat("This summary is also returned in the file: results_summary_coloc_abf.csv\n")
  sink()
  
  #Save the results summary in a table which can be readily combined with other outputs
  Sum_abf<- t(enframe(c(traits,region=paste0("Chr", reg_range["chr"],":",reg_range["start"],"-",reg_range["stop"]),clc.abf$priors,clc.abf$summary)))
  Sum_abf[1,1:length(traits)] <- paste0("TraitID_",1:length(traits))
  
  write.table(Sum_abf,file=file.path(tabdir,"results_summary_coloc_abf.csv"),sep = ",",row.names=FALSE,col.names = FALSE,quote = FALSE)
  
  #Save PP.H4.abf summaries, with additional details to file
  sets_outpath<- file.path(tabdir,"coloc.susie_snpwise_PP_H4_abf.csv")
  
  #Store in plotdata option for potential plotting
  plotdata.abf <- sums1.region %>%
    as.data.frame() %>%
    dplyr::select(snp,pos) %>%
    right_join(clc.abf$results,by="snp")
  
  write.table(plotdata.abf,file=sets_outpath,sep = ",",row.names=FALSE)
  
  sink(file = logfile, append = T)
  cat("\nSNPwise posterior probabilities of being a shared variant for",paste(traits,collapse = " & "),"under coloc.abf are tabulated in:\n", basename(sets_outpath),"\n")
  sink()
  
  #Flag which coloc analysis has been performed 
  coloc_performed <- c(coloc_performed, "coloc.abf")
}

#If both susie calls are successful and credible sets identified, run coloc.susie.
#Note that plots will overwrite any from Coloc.abf.
if(!any(SusieFail) && all(sapply(susie_rep[1:2],function(x)x$csFound)) && opt$runMode %in% c("doBoth","trySusie")){
  ###run coloc.susie based on susie outputs and priors set
  clc<- do.call(coloc.susie,c(colocPriors$coloc.susie,list(dataset1=susie[[1]], dataset2=susie[[2]])))
  
  
  #Save the coloc abf results as a resource
  colocpath<- file.path(datadir,"colocalisation")
  if(!dir.exists(colocpath)){dir.create(colocpath)}
  saveRDS(clc,file=file.path(colocpath,paste0("coloc_susie_",paste0(traits,collapse="_"),".Rds")))

  sink(file = logfile, append = T)
  cat("------------------------------\n")
  cat("coloc.susie was performed with the following priors:\n")
  print(clc$priors)
  invisible(print(clc$summary)) #Call summary invisibly first to avoid triggering bug where no output is printed
  cat("coloc.susie results summary:\n")
  print(clc$summary)
  cat("This summary is also returned in the file: results_summary_coloc_susie.csv.\n")
  sink()
  
  #Save the results summary in a table which can be readily combined with other outputs
  if(nrow(clc$summary)>1){
    Sum_clcsusie<- c(traits,region=paste0("Chr", reg_range["chr"],":",reg_range["start"],"-",reg_range["stop"]),clc$priors) %>%
      t() %>%
      .[rep(1,nrow(clc$summary)),] %>%
      cbind(.,clc$summary)
  } else {
    Sum_clcsusie<- c(traits,region=paste0("Chr", reg_range["chr"],":",reg_range["start"],"-",reg_range["stop"]),clc$priors,clc$summary) %>%
      t()
  }
  colnames(Sum_clcsusie)[1:length(traits)] <- paste0("TraitID_",1:length(traits))
  
  write.table(Sum_clcsusie,file=file.path(tabdir,"results_summary_coloc_susie.csv"),sep = ",",row.names=FALSE,col.names = TRUE,quote = FALSE)
  
  coloc_performed <- c(coloc_performed, "coloc.susie") #Flag which coloc analysis have been performed 
}


######
### Prepare to plot the results of colocalisation analysis, and write table if coloc.susie is applied
#####

#For plotting, generate labels for SNPs with the top 5% posterior probability of being a shared variant
label_limit <- ceiling(length(snplist)*0.05)

#However, limit the top number of snps to 10 at most 
if(label_limit>10){
  label_limit <- 10
}

toPlot<- list()

if("coloc.abf" %in% coloc_performed){
  
  #Colour likely snps under the assumption that h4 is true: " https://chr1swallace.github.io/coloc/articles/a03_enumeration.html
  toPlot[[1]] <- plotdata.abf %>%
    arrange(desc(SNP.PP.H4)) %>%
    mutate(cs_coloc=cumsum(SNP.PP.H4),                                             #Establish coloc.credible set
           thresh=if_else(row_number() <= label_limit, as.character(snp),""), #Label top snps
           cs_coloc=case_when(row_number() == 1 ~ "within set",               #Top snp is always within set
                              lag(cs_coloc) < 0.95 ~ "within set",             #lag checks previous record. If this value is <0.95 then snp is in set
                              TRUE ~ "outside set"),
           cs_coloc= factor(cs_coloc,levels=c("within set","outside set")))
}

if("coloc.susie" %in% coloc_performed){
  
  #More descriptive results tabulation
  clc$results <- sums1.region %>%
    as.data.frame() %>%
    dplyr::select(snp,pos) %>%
    full_join(snp_CS,by="snp") %>%
    full_join(clc$results,by="snp") %>%
    rename(cs_susie=cs)
  
  #Save PP.H4 summaries, with additional details, to file
  sets_outpath<- file.path(tabdir,"coloc.susie_snpwise_PP_H4_abf.csv")
  write.table(clc$results,file=sets_outpath,sep = ",",row.names=FALSE)
  
  sink(file = logfile, append = T)
  cat("\nSNPwise posterior probabilities of being a shared variant for",paste(traits,collapse = " & "),"under coloc.susie are tabulated in:\n", basename(sets_outpath),"\n")
  sink()
  
  #Prepare plotting for each 'row' of coloc.susie
  for(i in 1:nrow(clc$summary)){
    
    #Extract a given plotdata column
    plotdata <- clc$results[,c(1:3,i+3)]
    #clc_col_index <- which(grepl("SNP.PP.H4",colnames(plotdata)))
    
    #Assign labels to top X% of SNPs, arranged by PP in column
    plotdata<- plotdata %>%
      arrange(desc(.[[4]])) %>%
      mutate(cs_coloc=cumsum(.[[4]]),                                                #Establish coloc.credible set
             thresh=if_else(row_number() <= label_limit, as.character(snp),""), #Label top snps
             cs_coloc=case_when(row_number() == 1 ~ "within set",               #Top snp is always within set
                                lag(cs_coloc) < 0.95 ~ "within set",             #lag checks previous record. If this value is <0.95 then snp is in set
                                TRUE ~ "outside set"),
             cs_coloc= factor(cs_coloc,levels=c("within set","outside set")))
      
  toPlot[[length(toPlot)+1]] <- plotdata
  }
  
}
sink(file = logfile, append = T)
cat("------------------------------\n")
sink()

######
### Produce plots recurrently across toPlot list
#####
for(i in 1:length(toPlot)){
  
  #Extract plotting dataframe
  clc_col_index <- grep("SNP.PP.H4",colnames(toPlot[[i]]),value = TRUE)
  plotdata<- toPlot[[i]] %>%
    rename(SNP.PP=all_of(clc_col_index))
  
  #Set parameters for loop according to whether a coloc.abf or coloc.susie analysis is being plotted
  if(("coloc.susie" %in% coloc_performed && !"coloc.abf" %in% coloc_performed) ||
     ("coloc.susie" %in% coloc_performed && "coloc.abf" %in% coloc_performed && i!=1)){
    
    #Identify the current analysis, for later logic checks
    current <- "susie"
    
    # #Set colour mapping and legend
    colourMapping = "cs_susie"
    nameColourLegend<- paste("SuSiE fine-mapping\n(Trait:",coveragePcent,"credible set)")
    
    #Determine filename for loop, first identify which cs are compared, then name accordingly
    if("coloc.abf" %in% coloc_performed){ 
      ind <- i-1
    } else {
      ind <- i
    }
    cs_index<- clc$summary[ind,c("idx1","idx2")]
    cs_label <- paste(traits,cs_index,sep=":")
    cs_filenm <- paste(paste(traits,cs_index,sep="cs"),collapse="_")
    
    filename<- file.path(figdir,paste0("coloc.susie_result_all_snps_",cs_filenm,".pdf"))
    
  } else {
    #Identify the current analysis, for later logic checks
    current <- "abf"
    
    # # #Set colour mapping and legend
    colourMapping <- NULL
    nameColourLegend <- NULL
    
    #Determine filename for loop
    cs_filenm <- ".abf"
    filename<- file.path(figdir,"coloc.abf_result_all_snps.pdf")
    
  }
  
  #Set shape mapping and legend
  shapeMapping <- "cs_coloc"
  nameShapeLegend <- "Colocalisation\n(95% credible set\nassuming shared\nvariant)"
  
  #Build all snps plot, add labels for snps
  snp_PP <- ggSummaryplot(yaxis="SNP.PP",
                          xlim=c(reg_range['start'],reg_range['stop']),
                          chr=reg_range['chr'],
                          dset=plotdata,
                          colourMapping=colourMapping,
                          shapeMapping=shapeMapping,
                          traits=traits,
                          facetTraits = FALSE,
                          nameColourLegend=nameColourLegend,
                          nameShapeLegend=nameShapeLegend,
                          build=paste0("GRCh",opt$genomeAlignment))$bpfigure +
    geom_text_repel(aes(label=thresh), max.overlaps = 20, na.rm=TRUE, show.legend = FALSE)
  
  #Saveplot
  ggsave(filename,snp_PP,device="pdf",units="mm",width=150,height=175)
  
  
  #### Replot colocalised snps based on nearby genes
  min_bp<-min(plotdata$pos[plotdata$cs_coloc=="within set"])-gene_window #10KB
  max_bp<-max(plotdata$pos[plotdata$cs_coloc=="within set"])+gene_window #10KB
  chr<- reg_range["chr"]
  
  #Extract genes within the start or stop positions within 
  #Genes_subset<-Genes[Genes$start_position > min_bp & Genes$end_position < max_bp & Genes$chromosome_name == chr,] %>%
  Genes_subset <- Genes[Genes$chromosome_name == chr & (
    (Genes$start_window > min_bp & Genes$start_window < max_bp) |
      (Genes$end_window > min_bp & Genes$end_window < max_bp) |
      (Genes$start_window < min_bp & Genes$end_window > max_bp)
  ),]
  
  #If nearby snps are found, do further plotting, otherwise write message
  if(nrow(Genes_subset)>0){

    #Save details for nearby genes
    sets_outpath<- file.path(tabdir,paste0("nearby_genes_coloc",cs_filenm,".csv"))
    Genes_subset %>%
      arrange(start_position) %>%
      dplyr::select(-c(start_window,end_window)) %>%
      write.table(.,file=sets_outpath,sep = ",",row.names=FALSE)
    
    sink(file = logfile, append = T)
    
    if(current=="susie"){
      cat("\nGenes located within a 10Kb window around the top 10% of snps from current pair of SuSiE credible sets are tabulated in: ", basename(sets_outpath),"\n")
    } else {
      cat("\nGenes located within a 10Kb window around the top 10% of coloc.abf snps are tabulated in: ", basename(sets_outpath),"\n")
    }
    sink()
    
    #If subsetting to named gene sources, generate the vector, and cat message to file if no rows would remain
    if(!is.null(opt$restrict_nearby_gene_plotting_source)){ 
      
      geneSources <-strsplit(opt$restrict_nearby_gene_plotting_source,split=",")[[1]] #String split on comma to identify sources
      
      if(sum(Genes_subset$external_gene_source %in% geneSources)==0){                                                     #If at least one gene remains, subset
        sink(file = logfile, append = T)
        cat("\nCould not subset nearby gene plotting by source since no genes remained after restricting to", paste0(geneSources,collapse=", "), "\n")
        sink()
      }
    } else {
      geneSources <- NULL
    }
    
    #Plot nearby genes - some steps integrated within the function have already been performed in the main script
    gene_near <- plotGenes(bp_range=c(min_bp,max_bp),chr=chr,genes=Genes_subset,geneSources=geneSources,
                           gene_tracks=opt$gene_tracks,nudge_y=0.3)
    
      
    
    #Narrow the snp plot xlim to match gene_near
    suppressMessages({ #Suppress warning about 'double-setting' xlim
      snp_PP_range <- snp_PP +
        xlim(gene_near$xlim)+
        theme(axis.title.x = element_blank(),
              axis.text.x = element_blank())
    })
    
    #If susie has been plotted, colouring is used to label Susie credible sets, adjust legend to include only snps in the new plot range
    if(current=="susie"){ 
      #To ensure consistent colouring when reassigning the colour factor, assign factor levels to specific colours
      levels<- levels(plotdata[[colourMapping]])
      col_levels <-ggpalette[1:length(levels)]
      names(col_levels)<- levels
      
      suppressMessages({ #Suppress warning about redoing existing legend
        snp_PP_range <- snp_PP_range +
          scale_colour_manual(na.value = "black", values=col_levels,
                              breaks = levels(droplevels(plotdata[which(plotdata$pos > gene_near$xlims[1] & plotdata$pos < gene_near$xlims[2]),colourMapping])))
      })
    }
    
    #Scale plot proportions according to number of genes plotted, but cap at 1, indicating equal proportions
    
    #To accommodate labelling when using track-based plotting, give extra buffer room per track
    if(is.null(gene_near$plot$data$track)){
      propor <- 0.05*length(gene_near$plot$data$external_gene_name)
    } else {
      propor <- 0.2*length(levels(gene_near$plot$data$track))
    }
    if(propor>1){propor <- 1}
    
    g_arr <- (snp_PP_range/gene_near$plot)+
      plot_layout(guides = 'collect',heights=c(1,propor))
    
    
    #If plotting the result of coloc.susie analysis, add extra info relevant to credible set assignments 
    if(current=="susie"){
      filename<- file.path(figdir,paste0("coloc_susie_likely_snps_with_genes",cs_filenm,".pdf"))
      
    } else {
      filename<- file.path(figdir,"coloc_abf_likely_snps_with_genes.pdf")
    }
    
    ggsave(filename,g_arr,device="pdf",units="mm",width=150,height=175)
    
  } else { #Conditional statement for when no nearby genes are found
    
    sink(file = logfile, append = T)
    
    if(("coloc.susie" %in% coloc_performed && !"coloc.abf" %in% coloc_performed) ||
       ("coloc.susie" %in% coloc_performed && "coloc.abf" %in% coloc_performed && i!=1)
    ){
      cat("\nNo genes were identified within a 10Kb window around snps from the current credible sets comparison:",gsub("_"," & ",cs_filenm),".\n")
    } else {
      cat("\nNo genes were identified within a 10Kb window around the top 10% of coloc.abf snps.\n")
    }
    sink()
    
  }
} 
} #Bracket indicating the end of the else condition performed when opt$runMode!="finemapOnly"

######
### Generate the global HTML report
######

### Get report information for each step

#P01 ...

#P03 ...

#Finemapping reports are handled per-trait. Therefore combine them into a single list
finemapReports<- grep("RMD_finemap_",ls(envir=.GlobalEnv),value=TRUE)
if(length(finemapReports)>0){
  P02<- lapply(finemapReports,get)
  names(P02) <- lapply(P02,function(x)x$trait)
}

#Create a concatenated list of all the params to pass to the parent report
prm<-list(P01=switch(exists("P01"),P01,NULL),
     P02=switch(exists("P02"),P02,NULL),
     P03=switch(exists("P03"),P03,NULL),
     rmdDir=file.path(normalizePath(opt$scriptsDir),"rmd"))

#Declare the file name
finalRep<- file.path(normalizePath(opt$out),"analysis_report.html")


#Render the parent report
renderReport(template=file.path(normalizePath(opt$scriptsDir),"rmd","parent_report.Rmd"),
             params="prm", #prm is passed to get() function
             outfile=finalRep
)

sink(file = logfile, append = T)
cat("------------------------------\n")
cat("An html report overviewing the complete analysis can be found in:", basename(finalRep))
cat("The report currently only contains the finemapping step. Please review this log for other steps and the plots directory for figures comparing across traits used for colocalisation analysis.\n")
sink()
